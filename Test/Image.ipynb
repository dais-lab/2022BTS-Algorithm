{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ec49c72",
   "metadata": {},
   "source": [
    "# 1. 필요한 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2702d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.applications import ResNet50, VGG16, EfficientNetB0\n",
    "from keras.layers import LSTM, RepeatVector, TimeDistributed, Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05152b86",
   "metadata": {},
   "source": [
    "# 2. Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c03f3",
   "metadata": {},
   "source": [
    "- 소리데이터를 이미지데이터를 변환한 한 것으로 이미지데이터 기반 데이터 이상탐지 테스트 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ae812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_data(Y_test, Y_pred, hyperparameter_file_name):\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "\n",
    "    for i in range(len(Y_pred)):\n",
    "        if Y_test[i] == 0 and Y_pred[i] == 0:\n",
    "            TN = TN + 1\n",
    "        elif Y_test[i] == 0 and Y_pred[i] == 1:\n",
    "            FP = FP + 1\n",
    "        elif Y_test[i] == 1 and Y_pred[i] == 0:\n",
    "            FN = FN + 1\n",
    "        elif Y_test[i] == 1 and Y_pred[i] == 1:\n",
    "            TP = TP + 1\n",
    "\n",
    "    row_data = {\"Accuracy\" : [accuracy_score(Y_test, Y_pred)],\n",
    "                \"F1_Score\" : [f1_score(Y_test, Y_pred)],\n",
    "                \"Recall\" : [recall_score(Y_test, Y_pred)],\n",
    "                \"Precision\" : [precision_score(Y_test, Y_pred)],\n",
    "                \"TN\" : [TN],\n",
    "                \"FP\" : [FP],\n",
    "                \"FN\" : [FN],\n",
    "                \"TP\" : [TP]}\n",
    "    df = pd.DataFrame(row_data)\n",
    "    df.to_csv(\"/BTS/result/Test_result/\" + hyperparameter_file_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_image_model(hyperparameter):\n",
    "    if hyperparameter[\"color\"] == \"rgb\":\n",
    "        input_tensor = Input(shape = (hyperparameter[\"size_width\"], hyperparameter[\"size_height\"], 3))\n",
    "    else:\n",
    "        input_tensor = Input(shape = (hyperparameter[\"size_width\"], hyperparameter[\"size_height\"], 1))\n",
    "\n",
    "    if hyperparameter[\"model\"] == \"CNN\" and hyperparameter[\"color\"] == \"rgb\":\n",
    "        input_CNN_tensor = (hyperparameter[\"size_width\"], hyperparameter[\"size_height\"], 3)\n",
    "    else :\n",
    "        input_CNN_tensor = (hyperparameter[\"size_width\"], hyperparameter[\"size_height\"], 1)\n",
    "\n",
    "    if hyperparameter[\"model\"] == \"CNN\":\n",
    "        training_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_CNN_tensor),\n",
    "            tf.keras.layers.MaxPool2D(2, 2),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D(2, 2),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D(2, 2),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D(2, 2),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D(2, 2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "    elif hyperparameter[\"model\"] == \"VGG16\":\n",
    "        training_model = VGG16(weights = None, include_top = False, input_tensor = input_tensor)\n",
    "\n",
    "        layer_dict = dict([(layer.name, layer) for layer in training_model.layers])\n",
    "\n",
    "        x = layer_dict['block5_pool'].output\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(4096, activation = 'relu')(x)\n",
    "        x = tf.keras.layers.Dense(4096, activation = 'relu')(x)\n",
    "        x = tf.keras.layers.Dense(1024, activation = 'relu')(x)\n",
    "        x = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "        training_model = Model(inputs = training_model.input, outputs = x)\n",
    "    \n",
    "    elif hyperparameter[\"model\"] == \"ResNet50\":\n",
    "        training_model = ResNet50(weights = None, include_top = False, input_tensor = input_tensor)\n",
    "\n",
    "        layer_dict = dict([(layer.name, layer) for layer in training_model.layers])\n",
    "        x = layer_dict['conv5_block3_out'].output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(1024, activation = 'relu')(x)\n",
    "        x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "        x = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "        training_model = Model(inputs = training_model.input, outputs = x)\n",
    "    \n",
    "    elif hyperparameter[\"model\"] == \"EfficientNetB0\":\n",
    "        training_model = EfficientNetB0(weights = None, include_top = False, input_tensor = input_tensor)\n",
    "        \n",
    "        layer_dict = dict([(layer.name, layer) for layer in training_model.layers])\n",
    "        \n",
    "        x = layer_dict['top_activation'].output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(1280, activation = 'relu')(x)\n",
    "        x = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "        training_model = Model(inputs = training_model.input, outputs = x)\n",
    "\n",
    "    return training_model\n",
    "\n",
    "def image_training(training_model, hyperparameter, hyperparameter_file_name, X_train, X_val, y_train, y_val):\n",
    "\n",
    "    class CustomCallback(keras.callbacks.Callback):\n",
    "            def on_train_begin(self, logs = None):\n",
    "                raw_data = {'epoch' : [],\n",
    "                            'train_loss' : [],\n",
    "                            'train_accuracy' : [],\n",
    "                            'validation_loss' : [],\n",
    "                            'validation_accuracy': [],\n",
    "                            'timestamp' : []}\n",
    "                df = pd.DataFrame(raw_data)\n",
    "                df.to_csv(\"/BTS/process_log/\" + hyperparameter_file_name + \".csv\", index = False)\n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                now = datetime.now()\n",
    "                df = pd.read_csv(\"/BTS/process_log/\" + hyperparameter_file_name + \".csv\")\n",
    "                df.loc[-1]=[epoch, logs[\"loss\"], logs[\"binary_accuracy\"], logs[\"val_loss\"], logs[\"val_binary_accuracy\"], now.timestamp()]\n",
    "                df.to_csv(\"/BTS/process_log/\" + hyperparameter_file_name + \".csv\", index = False)\n",
    "            def on_train_end(self, epoch, logs=None):\n",
    "                df = pd.read_csv(\"/BTS/process_log/\" + hyperparameter_file_name + \".csv\")\n",
    "                df.loc[-1]=[hyperparameter[\"epochs\"], 0, 0, 0, 0, 0]\n",
    "                df.to_csv(\"/BTS/process_log/\" + hyperparameter_file_name + \".csv\", index = False)\n",
    "    \n",
    "    filename = ('/BTS/training_model/' + \"training_model(\" + hyperparameter_file_name + \").h5\")\n",
    "    checkpoint = ModelCheckpoint(filename, monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'auto')\n",
    "    earlystopping = EarlyStopping(monitor = 'val_loss', patience = 30)\n",
    "\n",
    "    training_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = hyperparameter[\"learning_rate\"]),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics = tf.keras.metrics.BinaryAccuracy())\n",
    "\n",
    "    training_model.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = hyperparameter[\"batch_size\"], epochs = hyperparameter[\"epochs\"], callbacks = [checkpoint, earlystopping, CustomCallback()])\n",
    "\n",
    "def image_test(hyperparameter_file_name, X_test, y_test):\n",
    "    model_path = \"/BTS/training_model/training_model(\" + hyperparameter_file_name + \").h5\"\n",
    "    model = keras.models.load_model(model_path)\n",
    "    y_pred = model.predict(X_test)\n",
    "    temp = []\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] > 0.5:\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    y_pred = temp\n",
    "    row_data = {\"y_test\" : y_test, \"y_pred\" : y_pred}\n",
    "    score = pd.DataFrame(row_data)\n",
    "    return score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
