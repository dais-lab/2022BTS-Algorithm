{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a16436",
   "metadata": {},
   "source": [
    "# 1. 필요한 패키지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b477cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import splitfolders\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ba262",
   "metadata": {},
   "source": [
    "# 2. Sound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94365d5d",
   "metadata": {},
   "source": [
    "- librosa를 이용한 소리데이터 이상탐지 데이터전처리 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaab89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_Mel_Spectrogram(Sound_path, Image_path):\n",
    "    \"\"\"\n",
    "    wav 파일을 image 파일로 변환 후 저장하는 함수입니다.\n",
    "    \"\"\"\n",
    "\n",
    "    frame_length = 0.025\n",
    "    frame_stride = 0.010\n",
    "\n",
    "    for filename in os.listdir(Sound_path):\n",
    "        y, sr = librosa.load(os.path.join(Sound_path, filename), sr = None)\n",
    "\n",
    "        input_nfft = int(round(sr*frame_length))\n",
    "        input_stride = int(round(sr*frame_stride))\n",
    "\n",
    "        S = librosa.feature.melspectrogram(y = y, n_mels = 40, n_fft = input_nfft, hop_length = input_stride)\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.specshow(librosa.power_to_db(S, ref=np.max), sr = sr, hop_length=input_stride)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(Image_path+filename+'.png', bbox_inches = 'tight', pad_inches = 0)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22dee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Data_split(image_path, split_path):\n",
    "    \"\"\"\n",
    "    Image data 8:1:1 비율로 분리\n",
    "    \"\"\"\n",
    "    splitfolders.ratio(image_path,\n",
    "    split_path, ratio = (0.8, 0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sound_Data_Generator(train_path, validation_path, test_path, hyperparameter):\n",
    "    \"\"\"\n",
    "    ImageDataGenerator() 함수로 모든 image에 labeling 하고, 이미지를 trianing 할 수 있게 수치화해줌\n",
    "    \"\"\"\n",
    "    data_generator = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size = (hyperparameter[\"size_width\"], hyperparameter[\"size_height\"]),\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = 'binary',\n",
    "        batch_size = 1)\n",
    "    \n",
    "    n_img = train_generator.n\n",
    "    steps = n_img//1\n",
    "\n",
    "    imgs, labels = [], []\n",
    "    \n",
    "    for i in range(steps):\n",
    "        a, b = train_generator.next()\n",
    "        imgs.extend(a)\n",
    "        labels.extend(b)\n",
    "\n",
    "    X_train = np.asarray(imgs)\n",
    "    y_train = np.asarray(labels)\n",
    "\n",
    "    validation_generator = data_generator.flow_from_directory(\n",
    "        validation_path,\n",
    "        target_size = (hyperparameter[\"size_width\"], hyperparameter[\"size_height\"]),\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = 'binary',\n",
    "        batch_size = 1)\n",
    "\n",
    "    n_img = validation_generator.n\n",
    "    steps = n_img//1\n",
    "\n",
    "    imgs, labels = [], []\n",
    "\n",
    "    for i in range(steps):\n",
    "        a, b = validation_generator.next()\n",
    "        imgs.extend(a)\n",
    "        labels.extend(b)\n",
    "\n",
    "    X_val = np.asarray(imgs)\n",
    "    y_val = np.asarray(labels)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size = (hyperparameter[\"size_width\"], hyperparameter[\"size_height\"]),\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = 'binary',\n",
    "        batch_size = 1)\n",
    "    \n",
    "    n_img = test_generator.n\n",
    "    steps = n_img//1\n",
    "\n",
    "    imgs, labels = [], []\n",
    "\n",
    "    for i in range(steps):\n",
    "        a, b = test_generator.next()\n",
    "        imgs.extend(a)\n",
    "        labels.extend(b)\n",
    "\n",
    "    X_test = np.asarray(imgs)\n",
    "    y_test = np.asarray(labels)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
